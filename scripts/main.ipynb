{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f751a45",
   "metadata": {},
   "source": [
    "## Imports And Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66a0423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../data/summary_stats\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce5eeb",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b1a55",
   "metadata": {},
   "source": [
    "### Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ccd2ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 272524\n",
      "Rows after full filtering: 267888\n"
     ]
    }
   ],
   "source": [
    "# === Load and normalize ===\n",
    "df = pd.read_csv(\"../data/crash_data_2014_to_2024.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "\n",
    "# === 1️⃣ Remove NaN entries in key vars ===\n",
    "key_cols = [\n",
    "    \"county_id\",\n",
    "    \"crash_severity_id\",\n",
    "    \"light_condition_id\",\n",
    "    \"weather_condition_id\",\n",
    "    \"roadway_surf_condition_id\"\n",
    "]\n",
    "df_clean = df.dropna(subset=key_cols)\n",
    "\n",
    "# === 2️⃣ Remove invalid category codes ===\n",
    "invalid_codes = [8, 89, 96, 97, 98, 99, 88, \"U\", \"Unknown\", \"Not Provided\", \"Invalid\"]\n",
    "for col in key_cols[1:]:  # skip county_id\n",
    "    df_clean = df_clean[~df_clean[col].isin(invalid_codes)]\n",
    "\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Rows after full filtering: {len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4805cce",
   "metadata": {},
   "source": [
    "### Create Summary CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d4515a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === County ID → Name mapping ===\n",
    "county_map = {\n",
    "    11: \"Davis\",\n",
    "    35: \"Salt Lake\",\n",
    "    49: \"Utah\",\n",
    "    53: \"Washington\",\n",
    "    57: \"Weber\"\n",
    "}\n",
    "\n",
    "df[\"county_name\"] = df[\"county_id\"].map(county_map)\n",
    "df = df[df[\"county_name\"].notna()]  # keep only the 5 target counties\n",
    "\n",
    "# === Variable label mappings ===\n",
    "severity_map = {\n",
    "    1: \"No injury / PDO\",\n",
    "    2: \"Possible injury\",\n",
    "    3: \"Suspected Minor Injury\",\n",
    "    4: \"Suspected Serious Injury\",\n",
    "    5: \"Fatal\"\n",
    "}\n",
    "\n",
    "light_map = {\n",
    "    1: \"Daylight\",\n",
    "    2: \"Dark - Lighted\",\n",
    "    3: \"Dark - Not Lighted\",\n",
    "    4: \"Dark - Unknown Lighting\",\n",
    "    5: \"Dawn\",\n",
    "    6: \"Dusk\"\n",
    "}\n",
    "\n",
    "weather_map = {\n",
    "    1: \"Clear\",\n",
    "    2: \"Cloudy\",\n",
    "    3: \"Rain\",\n",
    "    4: \"Snowing\",\n",
    "    5: \"Blowing Snow\",\n",
    "    6: \"Sleet, Hail\",\n",
    "    7: \"Fog, Smog\",\n",
    "    8: \"Severe Crosswinds\",\n",
    "    9: \"Blowing Sand / Dirt\"\n",
    "}\n",
    "\n",
    "road_map = {\n",
    "    1: \"Dry\",\n",
    "    2: \"Wet\",\n",
    "    3: \"Snow\",\n",
    "    4: \"Slush\",\n",
    "    5: \"Ice / Frost\",\n",
    "    6: \"Water\",\n",
    "    7: \"Mud\",\n",
    "    8: \"Sand / Dirt / Gravel\",\n",
    "    9: \"Oil\",\n",
    "    10: \"Dirt\",\n",
    "    11: \"Gravel\",\n",
    "    12: \"Sand\",\n",
    "    97: \"Other\"\n",
    "}\n",
    "\n",
    "# === Helper function to make county-level proportion table ===\n",
    "def make_summary(df, var, mapping, var_label):\n",
    "    tmp = df[[var, \"county_name\"]].copy()\n",
    "    tmp[var] = tmp[var].map(mapping)\n",
    "\n",
    "    # Count occurrences by county and category\n",
    "    counts = tmp.groupby([\"county_name\", var]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Convert to proportions (row sums = 1 per county)\n",
    "    props = counts.div(counts.sum(axis=1), axis=0).T.reset_index()\n",
    "\n",
    "    # The first column now contains category labels — name it explicitly\n",
    "    props.rename(columns={props.columns[0]: \"Category\"}, inplace=True)\n",
    "\n",
    "    # Add the numeric code dynamically using the mapping dictionary\n",
    "    label_to_code = {v: k for k, v in mapping.items()}\n",
    "    props.insert(0, \"Code\", props[\"Category\"].map(label_to_code))\n",
    "\n",
    "    # Fill any missing labels as 'Unknown'\n",
    "    props[\"Category\"] = props[\"Category\"].fillna(\"Unknown\")\n",
    "\n",
    "    return props\n",
    "\n",
    "\n",
    "# === Generate summaries ===\n",
    "severity_summary = make_summary(df, \"crash_severity_id\", severity_map, \"Crash Severity\")\n",
    "light_summary = make_summary(df, \"light_condition_id\", light_map, \"Light Condition\")\n",
    "weather_summary = make_summary(df, \"weather_condition_id\", weather_map, \"Weather Condition\")\n",
    "road_summary = make_summary(df, \"roadway_surf_condition_id\", road_map, \"Roadway Surface Condition\")\n",
    "\n",
    "# === Combine all summaries into one DataFrame ===\n",
    "severity_summary[\"Variable\"] = \"Crash Severity\"\n",
    "light_summary[\"Variable\"] = \"Light Condition\"\n",
    "weather_summary[\"Variable\"] = \"Weather Condition\"\n",
    "road_summary[\"Variable\"] = \"Road Surface\"\n",
    "\n",
    "combined = pd.concat(\n",
    "    [severity_summary, light_summary, weather_summary, road_summary],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Move \"Variable\" to the front\n",
    "cols = [\"Variable\", \"Code\", \"Category\"] + [c for c in combined.columns if c not in [\"Variable\", \"Code\", \"Category\"]]\n",
    "combined = combined[cols]\n",
    "\n",
    "# === Save one combined CSV ===\n",
    "combined.to_csv(\"../data/summary_stats/summary_all_variables.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b256a4c",
   "metadata": {},
   "source": [
    "### Add Standard Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c28881ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load your combined summary file ===\n",
    "df = pd.read_csv(\"../data/summary_stats/summary_all_variables.csv\")\n",
    "\n",
    "# === Total number of observations (Salt Lake crashes) ===\n",
    "n = 267888\n",
    "\n",
    "# === Compute binomial standard error for each proportion ===\n",
    "# Formula: SE = sqrt(p * (1 - p) / n)\n",
    "df[\"SE\"] = np.sqrt(df[\"Salt Lake\"] * (1 - df[\"Salt Lake\"]) / n)\n",
    "\n",
    "# === Optional: round for readability ===\n",
    "df[\"Salt Lake\"] = df[\"Salt Lake\"].round(6)\n",
    "df[\"SE\"] = df[\"SE\"].round(6)\n",
    "\n",
    "# === Save new version ===\n",
    "df.to_csv(\"../data/summary_stats/summary_all_variables_with_SE.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
